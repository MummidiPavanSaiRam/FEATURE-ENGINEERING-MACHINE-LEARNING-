{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "1. What is a parameter?\n",
        "- A parameter is like a placeholder or variable that a function, method, or model uses to receive input values when it runs."
      ],
      "metadata": {
        "id": "fbSk9gDzIndO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "2. What is correlation?\n",
        "- Correlation is a statistical measure that tells you how strongly two variables are related and in which direction."
      ],
      "metadata": {
        "id": "-w0GPFk1Inmz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. What does negative correlation mean?\n",
        "- Negative correlation means that as one variable increases, the other decreases.\n"
      ],
      "metadata": {
        "id": "SRYHgQKkInpa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Define Machine Learning. What are the main components in Machine Learning?\n",
        "- Machine Learning (ML) is a branch of artificial intelligence that enables systems to learn patterns from data and make predictions or decisions without being explicitly programmed.\n",
        "\n",
        "- Dataset The collection of data used for training and testing the model Example: Historical sales data, images, sensor readings.\n",
        "\n",
        "- Features The measurable inputs (variables) used to make predictions.\n",
        "Example: Age, salary, education level in an employee dataset.\n",
        "\n",
        "- Model The mathematical or computational structure that learns the patterns from data.\n",
        "Example: Linear regression, decision trees, neural networks.\n",
        "\n",
        "- Training The process of feeding data to the model so it can learn the relationships between features and the target output.\n",
        "\n",
        "- Evaluation Measuring how well the model performs using metrics (e.g., accuracy, precision, recall, RMSE) on unseen test data.\n",
        "\n",
        "- Prediction / Inference Using the trained model to make decisions or predictions on new data."
      ],
      "metadata": {
        "id": "xz8ja_6aIns4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "5. How does loss value help in determining whether the model is good or not?\n",
        "- The **loss value** measures how far the model’s predictions are from the actual values — a **smaller loss** means better predictions, while a **larger loss** means the model is performing poorly.\n"
      ],
      "metadata": {
        "id": "USeS4MrtKdgo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. What are continuous and categorical variables?\n",
        "- The continoues variables are  Numerical data that can take any value within a range, including decimals.\n",
        "Example: Height (172.5 cm), temperature (36.8°C), weight (65.2 kg)., categorical variables are data which represensts  Data that represent groups or categories rather than numbers with mathematical meaning,Example: Gender (Male/Female), blood type (A, B, AB, O), city names."
      ],
      "metadata": {
        "id": "RW7Vl4EfKddN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "7. How do we handle categorical variables in Machine Learning? What are the common techniques?\n",
        "\n",
        "- Categorical variables in Machine Learning are handled by encoding them into numerical form so models can process them.\n",
        "\n",
        "- Label Encoding - Assigns a unique integer to each category.\n",
        "- One-Hot Encoding - Creates separate binary columns for each category.\n",
        "- Target Encoding - Replaces each category with the mean of the target variable for that category"
      ],
      "metadata": {
        "id": "7rRo_m2IKdbR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "8. What do you mean by training and testing a dataset?\n",
        "- Training datasets means providing them Datasets and make them learn and testing data sets help the data sets work in the field."
      ],
      "metadata": {
        "id": "VOHw2hb8KdX8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "9. What is sklearn.preprocessing?\n",
        "- sklearn.preprocessing is a module in Scikit-learn that provides tools to prepare and transform raw data into a suitable format for machine learning models."
      ],
      "metadata": {
        "id": "YidJH91eKdUc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "10. What is a Test set?\n",
        "- A test set is a portion of your dataset that is kept aside and not used during training, and is used only to evaluate how well your trained machine learning model performs on completely unseen data."
      ],
      "metadata": {
        "id": "g9ADTrE2KdQ5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "11. How do we split data for model fitting (training and testing) in Python?\n",
        "- In Python, you can split data into training and testing sets using train_test_split from sklearn.model_selection."
      ],
      "metadata": {
        "id": "M-warb8NKdOZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "\n",
        "# Example dataset\n",
        "data = pd.DataFrame({\n",
        "    'Feature1': [1, 2, 3, 4, 5, 6],\n",
        "    'Feature2': [10, 20, 30, 40, 50, 60],\n",
        "    'Target':   [0, 1, 0, 1, 0, 1]\n",
        "})\n",
        "\n",
        "# Separate features (X) and target (y)\n",
        "X = data[['Feature1', 'Feature2']]\n",
        "y = data['Target']\n",
        "\n",
        "# Split data (80% training, 20% testing)\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "print(\"Training set size:\", len(X_train))\n",
        "print(\"Test set size:\", len(X_test))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4IS6m9cJYaUC",
        "outputId": "72da3b14-7dc4-4e58-d417-268bc60fce0c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set size: 4\n",
            "Test set size: 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "12. How do you approach a Machine Learning problem?\n",
        "- Approach a machine learning problem by understanding the goal, preparing and splitting the data, selecting and training a model, evaluating its performance, and then deploying and monitoring it.\n"
      ],
      "metadata": {
        "id": "PWyBaLJSKdMA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "13. Why do we have to perform EDA before fitting a model to the data?\n",
        "- We perform EDA before fitting a model to **understand the data’s structure, quality, and patterns**, so we can clean, preprocess, and choose the right modeling approach for better and more reliable results.\n"
      ],
      "metadata": {
        "id": "itOOG-bnKdJV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "14. How can you find correlation between variables in Python?\n",
        "- In Python, you can find correlation between variables using `pandas.DataFrame.corr()` or statistical functions like `scipy.stats.pearsonr()`.\n"
      ],
      "metadata": {
        "id": "qGK5gCGYMn60"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "15. What is causation? Explain difference between correlation and causation with an example.\n",
        "- Causation means that a change in one variable directly causes a change in another variable.\n",
        "-Correlation Shows that two variables move together, Causation"
      ],
      "metadata": {
        "id": "2mpwO2yEMn4L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "16. What is an Optimizer? What are different types of optimizers? Explain each with an example.\n",
        "- An optimizer is like a “coach” for your machine learning model — it tells the model how to change its settings (weights) so it can make better predictions and reduce mistakes (loss).\n",
        "\n",
        "- Gradient Descent Checks the whole data, sees how wrong the model is, and moves slowly in the direction that reduces error.\n",
        "Think: Walking slowly down a hill to reach the lowest point.\n",
        "\n",
        "- Stochastic Gradient Descent (SGD)\n",
        "Looks at one example at a time and updates quickly.\n",
        "Think: Running down the hill using small random steps — faster but a bit shaky.\n",
        "\n",
        "- Mini-Batch Gradient Descent\n",
        "Looks at small groups of data at a time — balance between speed and stability.\n",
        "\n",
        "- Momentum\n",
        "Remembers the previous direction and speeds up if moving the same way, so it doesn’t get stuck.\n",
        "Think: Rolling a ball down a hill — it gains speed.\n",
        "\n",
        "- RMSProp\n",
        "Adjusts the step size for each weight separately so that tricky areas are handled better.\n",
        "\n",
        "- Adam\n",
        "The “smart” one — mixes Momentum and RMSProp, so it’s usually fast and stable.\n",
        "This is the most commonly used in deep learning.\n",
        "\n"
      ],
      "metadata": {
        "id": "_TogOmCZMn1s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "17. What is sklearn.linear_model ?\n",
        "- sklearn.linear_model is a part of Scikit-learn that contains ready-to-use tools for building linear models — models that make predictions by combining input features in a straight-line way.\n",
        "\n",
        "- Example: Linear regression, logistic regression, ridge regression, etc.\n"
      ],
      "metadata": {
        "id": "vi6zKH5SMnzP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "18. What does model.fit() do? What arguments must be given?\n",
        "- model.fit() is the function that trains your machine learning model — it feeds the training data into the model so it can learn patterns and relationships\n",
        "\n",
        "- Arguments you must give X → Features (input data)\n",
        "Example: [[1, 2], [3, 4], [5, 6]]\n",
        "\n",
        "- y → Target values (labels/output) Example: [0, 1, 0]"
      ],
      "metadata": {
        "id": "BmD6rIkJMnwm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "19. What does model.predict() do? What arguments must be given?\n",
        "- model.predict() takes new input data and uses the trained model to give the predicted output values.\n",
        "\n",
        "- Arguments you must give\n",
        "- X → The features (input data) for which you want predictions.\n",
        "\n",
        "- Example: [[2, 3], [4, 5]]"
      ],
      "metadata": {
        "id": "h11GE4CfMnt_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "20. What is feature scaling? How does it help in Machine Learning?\n",
        "- Feature scaling is the process of adjusting numerical feature values to a common scale without changing their relative differences.\n",
        "\n",
        "- Many algorithms (like KNN, SVM, Gradient Descent) work better when features are on a similar scale.\n",
        "\n",
        "- Prevents features with large numbers from dominating those with smaller numbers.\n",
        "\n",
        "- Speeds up model training and improves convergence."
      ],
      "metadata": {
        "id": "zt0b_2DkMno3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "21. How do we perform scaling in Python?\n",
        "-"
      ],
      "metadata": {
        "id": "Ynrnn-EFMnmZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import numpy as np\n",
        "\n",
        "data = np.array([[20, 30000], [25, 50000], [30, 80000]])\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "scaled_data = scaler.fit_transform(data)\n",
        "print(scaled_data)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kdM19rPmYKvi",
        "outputId": "39460db9-68e3-41c9-bc85-eb99f1ce8125"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.  0. ]\n",
            " [0.5 0.4]\n",
            " [1.  1. ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "data = np.array([[20, 30000], [25, 50000], [30, 80000]])\n",
        "\n",
        "scaler = StandardScaler()\n",
        "scaled_data = scaler.fit_transform(data)\n",
        "print(scaled_data)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P1pxapRtYNgm",
        "outputId": "2735438b-88b7-439f-d6a2-98156495caee"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[-1.22474487 -1.13554995]\n",
            " [ 0.         -0.16222142]\n",
            " [ 1.22474487  1.29777137]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "22. What is sklearn.preprocessing?\n",
        "- sklearn.preprocessing is a module in Scikit-learn that provides tools to prepare and transform raw data into a suitable format for machine learning models."
      ],
      "metadata": {
        "id": "G2Q-ZbdtMnjh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "23. How do we split data for model fitting (training and testing) in Python?\n",
        "- We split data into training and testing sets in Python using train_test_split from sklearn.model_selection.\n",
        "\n"
      ],
      "metadata": {
        "id": "W0WzX7aYMng7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "\n",
        "# Sample dataset\n",
        "data = pd.DataFrame({\n",
        "    'Feature1': [1, 2, 3, 4, 5, 6],\n",
        "    'Feature2': [10, 20, 30, 40, 50, 60],\n",
        "    'Target':   [0, 1, 0, 1, 0, 1]\n",
        "})\n",
        "\n",
        "# Separate features and target\n",
        "X = data[['Feature1', 'Feature2']]\n",
        "y = data['Target']\n",
        "\n",
        "# Split into 80% train and 20% test\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "print(\"Training size:\", len(X_train))\n",
        "print(\"Testing size:\", len(X_test))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nsi0vdr4YqNp",
        "outputId": "ebd44d6c-a527-4a7a-bd77-f1489b4e01b3"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training size: 4\n",
            "Testing size: 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "24. Explain data encoding\n",
        "- Data encoding is the process of converting categorical (text or label) data into numerical form so that machine learning models can understand and use it.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "84QAwf6HMneH"
      }
    }
  ]
}